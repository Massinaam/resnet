import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from models import resnet
import torch.nn.utils.prune as prune
import matplotlib.pyplot as plt
from torch.amp import autocast
import torch.optim as optim

# Configuration du device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Pr√©traitement des donn√©es
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
])

# Chargement des datasets
trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=4)

testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
testloader = DataLoader(testset, batch_size=32, shuffle=False, num_workers=4)

# Initialisation du mod√®le
model = resnet.ResNet18().to(device)

# Charger les poids du mod√®le sauvegard√©
model.load_state_dict(torch.load("comb.pth"))
model = model.half().to(device)  # Appliquer la quantification en half precision

# Pruning structur√© et non structur√© du mod√®le
def prune_model(model, pruning_ratio=0.2, structured=True):
    for name, module in model.named_modules():
        if isinstance(module, nn.Conv2d):
            if structured:
                # Pruning structur√© : suppression de certains filtres
                prune.ln_structured(module, name='weight', amount=pruning_ratio, dim=0, n=1)
                prune.remove(module, 'weight')  # Applique d√©finitivement le pruning structur√©
            else:
                # Pruning non structur√© : suppression de certains poids
                prune.l1_unstructured(module, name='weight', amount=pruning_ratio)
                prune.remove(module, 'weight')  # Applique d√©finitivement le pruning non structur√©
        elif isinstance(module, nn.Linear):
            if structured:
                # Pruning structur√© : suppression de certains neurones
                prune.ln_structured(module, name='weight', amount=pruning_ratio, dim=0, n=1)
                prune.remove(module, 'weight')  # Applique d√©finitivement le pruning structur√©
            else:
                # Pruning non structur√© : suppression de certains poids
                prune.l1_unstructured(module, name='weight', amount=pruning_ratio)
                prune.remove(module, 'weight')  # Applique d√©finitivement le pruning non structur√©

# Appliquer le pruning structur√© et non structur√© sur le mod√®le
prune_model(model, pruning_ratio=0.2, structured=False)  # Applique le pruning structur√©

# Pruning stats et plot
def print_pruning_stats(model):
    nonzero = 0
    total = 0
    for param in model.parameters():
        nonzero += param.nonzero().size(0)
        total += param.numel()
    
    sparsity = 100 * (1 - nonzero / total)
    print(f"üìä Param√®tres non nuls : {nonzero:,} / {total:,}")
    print(f"üìâ Sparsit√© du mod√®le : {sparsity:}%")

# Initialisation de l'optimiseur (SGD)
optimizer = optim.SGD(model.parameters(), lr=0.0358408115435323, weight_decay=0.002345625688196673)

# Scheduler de taux d'apprentissage
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=12, gamma=0.28261595872305967)

# Crit√®re de perte
criterion = nn.CrossEntropyLoss()

for epoch in range(5):  # 5 epochs suffisent souvent
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0
    for inputs, labels in trainloader:
        inputs, labels = inputs.to(device), labels.to(device)
        inputs = inputs.half()  # Tr√®s important !

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()

    scheduler.step()  # Mise √† jour du learning rate
    
    print(f"üîß Finetuning Epoch {epoch+1}, Loss: {running_loss / len(trainloader):.4f}, Accuracy: {100 * correct / total:.2f}%")


# Fonction d'√©valuation avec autocast
def evaluate_model(model, testloader):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for inputs, labels in testloader:
            # D√©placer les entr√©es et les labels sur le m√™me p√©riph√©rique que le mod√®le
            inputs, labels = inputs.to(device), labels.to(device)
            inputs = inputs.half()  # Convertir les donn√©es d'entr√©e en half precision

            # Utiliser autocast pour g√©rer la conversion en half precision pendant l'inf√©rence
            with autocast(device_type='cuda', dtype=torch.half):
                outputs = model(inputs)

            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

    print(f"Accuracy on test set: {100 * correct / total:.2f}%")

# √âvaluation sur le test set
evaluate_model(model, testloader)

# Calcul du nombre de param√®tres
def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)

# Calcul des op√©rations MACs
def count_macs(model, input_size=(3, 32, 32)):
    x = torch.ones(1, *input_size).half().to(device)  # dummy input compatible half precision
    macs = 0
    
    def count_conv_macs(module, input, output):
        nonlocal macs
        if isinstance(module, nn.Conv2d):
            height_out, width_out = output.shape[2], output.shape[3]
            kernel_size = module.kernel_size[0] * module.kernel_size[1]
            macs += (height_out * width_out) * kernel_size * module.in_channels * module.out_channels

    def count_linear_macs(module, input, output):
        nonlocal macs
        if isinstance(module, nn.Linear):
            macs += input[0].shape[1] * output.shape[1]
    
    # Enregistrer les hooks
    hooks = []
    for module in model.modules():
        if isinstance(module, (nn.Conv2d, nn.Linear)):
            hook = module.register_forward_hook(count_conv_macs if isinstance(module, nn.Conv2d) else count_linear_macs)
            hooks.append(hook)
    
    model(x)  # Passage avant (dummy forward)

    # Supprimer les hooks correctement
    for hook in hooks:
        hook.remove()

    return macs

# Calcul du score selon la formule donn√©e
def compute_score_unstructured(model, quantization_ratio, params, ops):
    # Calculer la sparsit√© r√©elle (non structur√©e)
    total = 0
    nonzero = 0
    for param in model.parameters():
        total += param.numel()
        nonzero += param.nonzero().size(0)
    
    sparsity = 1 - (nonzero / total)  # Proportion de poids √† z√©ro
    p_u = sparsity
    p_s = 0.0  # Pas de structured pruning

    q_w = quantization_ratio  # Quantification des poids
    q_a = quantization_ratio  # Quantification des activations

    score = (1 - (p_s + p_u)) * (q_w / 32) * params / (5.6 * 10**6) + (1 - p_s) * (max(q_w, q_a) / 32) * ops / (2.8 * 10**8)
    return score, sparsity


def plot_pruning_sparsity_by_layer(model):
    layer_names = []
    sparsity_values = []

    for name, module in model.named_modules():
        if isinstance(module, (nn.Conv2d, nn.Linear)):
            nonzero = 0
            total = 0
            for param in module.parameters():
                nonzero += param.nonzero().size(0)
                total += param.numel()
            sparsity = 100 * (1 - nonzero / total) if total != 0 else 0

            layer_names.append(name)
            sparsity_values.append(sparsity)

    # Plot
    plt.figure(figsize=(14, 6))
    plt.bar(layer_names, sparsity_values)
    plt.xticks(rotation=90)
    plt.ylabel('Sparsit√© (%)')
    plt.xlabel('Couche')
    plt.title('Sparsit√© par couche apr√®s pruning')
    plt.grid(axis='y')
    plt.tight_layout()
    plt.savefig("sparsite_par_couche.png")
    plt.show()

# Exemple d'utilisation
params = count_parameters(model)  # Calcul du nombre de param√®tres du mod√®le
macs = count_macs(model, input_size=(3, 32, 32))  # Entr√©e de taille (3, 32, 32) pour CIFAR-10
score = compute_score_unstructured(model, quantization_ratio=16, params=params, ops=macs)

print(f"Nombre total de param√®tres du mod√®le : {params}")
print_pruning_stats(model)
print(f"Nombre approximatif de MACs : {macs}")
print(f"Score du mod√®le : {score}")

plot_pruning_sparsity_by_layer(model)
